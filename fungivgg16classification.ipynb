{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nfrom collections import Counter\nfrom timeit import default_timer as timer\n%load_ext autoreload\n%autoreload 2\n\n# !pip install numpy==1.22\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# from PIL import Image\n# import cv2\n\n!pip install ipywidgets\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport engine\nimport helper_functions\n\nfor filename in os.listdir('/kaggle/input'):\n    print(filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T08:14:10.321911Z","iopub.execute_input":"2023-09-13T08:14:10.322220Z","iopub.status.idle":"2023-09-13T08:14:26.691797Z","shell.execute_reply.started":"2023-09-13T08:14:10.322196Z","shell.execute_reply":"2023-09-13T08:14:26.690423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torchinfo import summary\nimport time\n\nfrom tempfile import TemporaryDirectory\n\n# cudnn.benchmark = True\n# plt.ion() \nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:14:30.959616Z","iopub.execute_input":"2023-09-13T08:14:30.960271Z","iopub.status.idle":"2023-09-13T08:14:31.041917Z","shell.execute_reply.started":"2023-09-13T08:14:30.960216Z","shell.execute_reply":"2023-09-13T08:14:31.040973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup device agnostic code","metadata":{}},{"cell_type":"code","source":"# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:14:34.561932Z","iopub.execute_input":"2023-09-13T08:14:34.562346Z","iopub.status.idle":"2023-09-13T08:14:34.612860Z","shell.execute_reply.started":"2023-09-13T08:14:34.562304Z","shell.execute_reply":"2023-09-13T08:14:34.611314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merging test-train-valid directories\n\nAs we observed during data exploration the test and valid directories are not balanced although the train directory is. We decided to merge all the directories in one directory destination_dir = '/kaggle/working/all', perform cross-validation and evaluate the model using balanced accuracy.\n","metadata":{}},{"cell_type":"code","source":"# Define the directory path to check\ndirectory_to_check = '/kaggle/input/fungi-all'\n\n# Check if the directory exists\nif not os.path.exists(directory_to_check):\n    # Define the source and destination directories\n    source_base_dir = '/kaggle/input/microscopic-fungi-images'\n    destination_dir = '/kaggle/working/fungi-all'\n\n    # List of subdirectories to merge\n    subdirectories_to_merge = ['H1', 'H2', 'H3', 'H5', 'H6']\n\n    # Create the destination directory if it doesn't exist\n    if not os.path.exists(destination_dir):\n        os.makedirs(destination_dir)\n\n    # Loop through each of the train, test, and val directories\n    for dataset_dir in ['train', 'test', 'valid']:\n        # Loop through the subdirectories to merge\n        for subdirectory in subdirectories_to_merge:\n            # Define the source and destination paths\n            source_path = os.path.join(source_base_dir, dataset_dir, subdirectory)\n            destination_path = os.path.join(destination_dir, subdirectory)\n\n            # Create a directory for the class if it doesn't exist\n            if not os.path.exists(destination_path):\n                os.makedirs(destination_path)\n\n            # Copy the files from source to destination\n            for filename in os.listdir(source_path):\n                source_file = os.path.join(source_path, filename)\n                destination_file = os.path.join(destination_path, filename)\n                shutil.copy(source_file, destination_file)\n\n        # Define the directory path\n        all_directory = '/kaggle/working/fungi-all'\n\n    print(\"Files merged successfully.\")\n            \nelse:\n        all_directory = '/kaggle/input/fungi-all'\n        print(\"fungi-all exists\")\n\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:14:37.469900Z","iopub.execute_input":"2023-09-13T08:14:37.470285Z","iopub.status.idle":"2023-09-13T08:14:37.523375Z","shell.execute_reply.started":"2023-09-13T08:14:37.470229Z","shell.execute_reply":"2023-09-13T08:14:37.522519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of subdirectories to check\nsubdirectories_to_check = ['H1', 'H2', 'H3', 'H5', 'H6']\n\n# Loop through the subdirectories\nfor subdirectory in subdirectories_to_check:\n    subdirectory_path = os.path.join(all_directory, subdirectory)\n    \n    # Check if the directory exists\n    if os.path.exists(subdirectory_path):\n        # Count the number of files in the directory\n        num_files = len(os.listdir(subdirectory_path))\n        print(f\"Number of files in '{subdirectory}': {num_files}\")\n    else:\n        print(f\"'{subdirectory}' directory does not exist in '{all_directory}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:22.078922Z","iopub.execute_input":"2023-09-12T13:30:22.079356Z","iopub.status.idle":"2023-09-12T13:30:24.217768Z","shell.execute_reply.started":"2023-09-12T13:30:22.079323Z","shell.execute_reply":"2023-09-12T13:30:24.216224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data and Visualize them","metadata":{}},{"cell_type":"code","source":"DATA_DIR = all_directory\n\ndataset = ImageFolder(DATA_DIR)\nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:26.636719Z","iopub.execute_input":"2023-09-12T13:30:26.637388Z","iopub.status.idle":"2023-09-12T13:30:33.618515Z","shell.execute_reply.started":"2023-09-12T13:30:26.637355Z","shell.execute_reply":"2023-09-12T13:30:33.617321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dataset.targets\ndataset.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:36.996135Z","iopub.execute_input":"2023-09-12T13:30:36.997135Z","iopub.status.idle":"2023-09-12T13:30:37.068756Z","shell.execute_reply.started":"2023-09-12T13:30:36.997093Z","shell.execute_reply":"2023-09-12T13:30:37.067241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize a few randomly selected images","metadata":{}},{"cell_type":"code","source":"labels_map = {\n    0: \"H1\",\n    1: \"H2\",\n    2: \"H3\",\n    3: \"H5\",\n    4: \"H6\",\n}\n\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 5, 5\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(dataset), size=(1,)).item() # generate a random integer in the dataset range\n    img, label = dataset[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(labels_map[label])\n    plt.axis(\"off\")\n    plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:43.633858Z","iopub.execute_input":"2023-09-12T13:30:43.634255Z","iopub.status.idle":"2023-09-12T13:30:46.285426Z","shell.execute_reply.started":"2023-09-12T13:30:43.634224Z","shell.execute_reply":"2023-09-12T13:30:46.284323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the classes' distribution","metadata":{}},{"cell_type":"code","source":"img_per_class = dict(Counter(dataset.targets))\n\nplt.rcParams[\"figure.autolayout\"] = True\nplt.figure(figsize=(10,8))\nsns.set_style('whitegrid')\nax = sns.barplot(x=dataset.classes, y=[value for value in img_per_class.values()], color='blue', palette='hls')\nax.bar_label(ax.containers[0])\n\nplt.xlabel('Fungi Classes', fontsize=15)\nplt.ylabel(f'Images', fontsize=15)\n\n\nplt.suptitle(f'Distribution of image classes', fontsize=15)\nplt.savefig(f'/kaggle/working/classes_distribution.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:52.108752Z","iopub.execute_input":"2023-09-12T13:30:52.109187Z","iopub.status.idle":"2023-09-12T13:30:53.046449Z","shell.execute_reply.started":"2023-09-12T13:30:52.109152Z","shell.execute_reply":"2023-09-12T13:30:53.045139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Split into stratified train,val, test subsets and store into folders (Kiriakos' function)","metadata":{}},{"cell_type":"code","source":"def split_dataset(dataset, labels, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_seed=42):\n    if train_ratio + val_ratio + test_ratio != 1.0:\n        raise ValueError(\"The sum of train_ratio, val_ratio, and test_ratio should be 1.0\")\n        \n    # initial split\n    train_data, test_data, train_labels, test_labels = train_test_split(\n        dataset, labels, test_size=test_ratio, random_state=random_seed, stratify=labels)\n    remaining_ratio = val_ratio / (train_ratio + val_ratio)\n    # rain-validation split\n    train_data, val_data, train_labels, val_labels = train_test_split(\n        train_data, train_labels, test_size=remaining_ratio, random_state=random_seed, stratify=train_labels)\n    \n    return train_data, val_data, test_data","metadata":{"execution":{"iopub.status.busy":"2023-09-09T19:37:06.608912Z","iopub.execute_input":"2023-09-09T19:37:06.609668Z","iopub.status.idle":"2023-09-09T19:37:06.667913Z","shell.execute_reply.started":"2023-09-09T19:37:06.609631Z","shell.execute_reply":"2023-09-09T19:37:06.666784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained VGG16 and inspect\n\nLoad the vgg16 model available in torchvision and use the pretrained weights to do transfer learning. Reset final fully connected layer to output the classes of our dataset.\n\nFind the transforms the model used during training.","metadata":{}},{"cell_type":"code","source":"weights = models.VGG16_Weights.DEFAULT\nvgg16 = models.vgg16(weights=weights).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:30:58.142414Z","iopub.execute_input":"2023-09-12T13:30:58.142846Z","iopub.status.idle":"2023-09-12T13:31:03.082621Z","shell.execute_reply.started":"2023-09-12T13:30:58.142813Z","shell.execute_reply":"2023-09-12T13:31:03.081336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(vgg16, \n        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n        verbose=0,\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n       )","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:08:04.638063Z","iopub.execute_input":"2023-09-12T12:08:04.638461Z","iopub.status.idle":"2023-09-12T12:08:09.631454Z","shell.execute_reply.started":"2023-09-12T12:08:04.638429Z","shell.execute_reply":"2023-09-12T12:08:09.630430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the tranforms that the prertained model used\ntransform=weights.transforms()\ntransform","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:08:19.885361Z","iopub.execute_input":"2023-09-12T12:08:19.886434Z","iopub.status.idle":"2023-09-12T12:08:19.950767Z","shell.execute_reply.started":"2023-09-12T12:08:19.886395Z","shell.execute_reply":"2023-09-12T12:08:19.949029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reset the final layer according to our number of classes.","metadata":{}},{"cell_type":"code","source":"# Set the manual seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# Get the length of class_names (one output unit for each class)\nclass_names = dataset.classes\noutput_shape = len(class_names)\n\n# get the number of input features for the final layer\nnum_ftrs = vgg16.classifier[6].in_features\n\n#Reset the final layer\nvgg16.classifier[6] = nn.Linear(num_ftrs, output_shape).to(device)\nvgg16 = vgg16.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:08:22.334810Z","iopub.execute_input":"2023-09-12T12:08:22.335208Z","iopub.status.idle":"2023-09-12T12:08:22.403599Z","shell.execute_reply.started":"2023-09-12T12:08:22.335174Z","shell.execute_reply":"2023-09-12T12:08:22.402561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(vgg16, \n        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n        verbose=0,\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n       )","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:44:53.996567Z","iopub.execute_input":"2023-09-12T09:44:53.996950Z","iopub.status.idle":"2023-09-12T09:44:54.109910Z","shell.execute_reply.started":"2023-09-12T09:44:53.996917Z","shell.execute_reply":"2023-09-12T09:44:54.108961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define a loss function and an optimizer\n\nWe chose to use a weighted cross entropy loss function to factor in the class imbalance. The weights we used are the percentages of images in each class.","metadata":{}},{"cell_type":"code","source":"total_imgs = len(dataset)\nnum_classes = len(dataset.classes)\nweights = torch.tensor([total_imgs/(class_imgs*num_classes) for class_imgs in img_per_class.values()]).to(device)\nprint(weights)\n\n# define the CrossEntropyLoss with weights\nloss_fn = nn.CrossEntropyLoss(weight=weights)\noptimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)\nexp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:08:28.955362Z","iopub.execute_input":"2023-09-12T12:08:28.956456Z","iopub.status.idle":"2023-09-12T12:08:29.064447Z","shell.execute_reply.started":"2023-09-12T12:08:28.956408Z","shell.execute_reply":"2023-09-12T12:08:29.063464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare dataset for cross validation\n\nLoad dataset with different transforms for the train and test splits. The transforms used are the ones the pretrained model weights were optimized on. Using the same transforms usually yields better performance when fine-tuning or using the model for feature extraction.\n\nIt is important to make sure that all values are scaled to the range [0..1] before we pass them to a neural network - it is the usual convention for data preparation, and all default weight initializations in neural networks are designed to work with this range. The transform.ToTensor() method does this tranformation.\n\nIt is important to note that all images should be scaled to the same size. The transform.Resize() method performs bilinear interpolation by default. Since our images are already in the size of 224x224 or smaller we decided not to first resize to 256 and then crop to 224 as the pretrained model suggests, in feat of losing information. We only resized them all to 224x224.\n\nNormalization is done with the ImageNet means and stds.\n\nThe test set will be held out separately for testing the final model after cross validation","metadata":{}},{"cell_type":"code","source":"# Define different transforms for the train and test sets\ntrain_transforms = transforms.Compose([\n    # data augmentations can go here\n    # transforms.RandomHorizontalFlip(),\n    # transforms.RandomRotation(10),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:37:20.609679Z","iopub.execute_input":"2023-09-12T13:37:20.610180Z","iopub.status.idle":"2023-09-12T13:37:20.703114Z","shell.execute_reply.started":"2023-09-12T13:37:20.610138Z","shell.execute_reply":"2023-09-12T13:37:20.701755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageFolder(DATA_DIR, transform=train_transforms)\ntest_dataset = ImageFolder(DATA_DIR, transform=test_transforms)\n\n# Create a list of indices from 0 to length of dataset\nindices = list(range(len(train_dataset)))\n\n# Retrieve the labels from the dataset\nlabels = [label for _, label in train_dataset]\n\n# Perform stratified split\ntrain_idx, test_idx = train_test_split(\n    indices,\n    test_size=0.15,  # 20% test, 80% train\n    stratify=labels,\n    random_state=42  # To ensure reproducibility\n)\n\n# Create train, test data with Subset using the indices generated above\ntrain_subset = Subset(train_dataset, train_idx)\ntrain_targets=[train_dataset.targets[i] for i in train_idx]\ntrain_targets_counts=Counter(train_targets)\nprint(train_targets_counts, len(train_subset))\n\ntest_subset = Subset(test_dataset, test_idx)\ntest_targets=[test_dataset.targets[i] for i in test_idx]\ntest_targets_counts=Counter(test_targets)\nprint(test_targets_counts, len(test_subset))\n\n# Create Test DataLoader\ntest_loader = DataLoader(test_subset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:37:23.813307Z","iopub.execute_input":"2023-09-12T13:37:23.813846Z","iopub.status.idle":"2023-09-12T13:37:48.112037Z","shell.execute_reply.started":"2023-09-12T13:37:23.813804Z","shell.execute_reply":"2023-09-12T13:37:48.110760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create dataloaders for 5 stratified folds of the training subset","metadata":{}},{"cell_type":"code","source":"# First we will create our train and test dataloaders using StratifiedKFold from sklearn\n\ndata_loaders = []\nclass_counts_per_split=[]\n\nreduced_dataset = train_subset\n\n# Perform cross-validation\nstratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nX = [dataset.imgs[i] for i in train_idx]\ny = [dataset.targets[i] for i in train_idx]\n\nfor i, (train_indices, val_indices) in enumerate(stratified_kfold.split(X, y)):\n    # Get the class labels for the training and testing sets of this split\n    train_classes = [y[idx] for idx in train_indices]\n    val_classes = [y[idx] for idx in val_indices]\n    \n    # Count the occurrences of each class in the training and testing sets\n    train_class_counts = Counter(train_classes)\n    val_class_counts = Counter(val_classes)\n    \n    # Append the counts to the list\n    class_counts_per_split.append((f\"Split {i+1}\", train_class_counts, val_class_counts))\n\n    # Create subsets of the dataset for training and testing using the indices\n    train_subset = Subset(reduced_dataset, train_indices)\n    val_subset = Subset(reduced_dataset, val_indices)\n    \n    # Create data loaders for training and testing\n    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n    \n    data_loaders.append((train_loader, val_loader))\n\n    # Print class counts for this split\n    print(f\"Split {i+1}:\")\n    print(\"Train Set Class Counts:\", train_class_counts)\n    print(\"Val Set Class Counts:\", val_class_counts)\n    print()\n    print(\"Train DataLoader:\", train_loader)\n    print(\"Val DataLoader:\", val_loader)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:37:51.532901Z","iopub.execute_input":"2023-09-12T13:37:51.533403Z","iopub.status.idle":"2023-09-12T13:37:51.634767Z","shell.execute_reply.started":"2023-09-12T13:37:51.533368Z","shell.execute_reply":"2023-09-12T13:37:51.633844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_loaders)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:48:38.059239Z","iopub.execute_input":"2023-09-12T09:48:38.059606Z","iopub.status.idle":"2023-09-12T09:48:38.118625Z","shell.execute_reply.started":"2023-09-12T09:48:38.059578Z","shell.execute_reply":"2023-09-12T09:48:38.117390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Perform Cross Validation\n\nWe can now evaluate the model using a loop to iterate through our 5 dataloaders. We append the results in `results_all` list ","metadata":{}},{"cell_type":"code","source":"# Set the random seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nresults_all=[]\n# init_weights = vgg16.state_dict()\n\nfor i in range(5):\n    print(f\"Split:{i}\")\n    start_time = timer()\n    \n    # Load the model\n    weights = models.VGG16_Weights.DEFAULT\n    vgg16 = models.vgg16(weights=weights).to(device)\n    num_ftrs = vgg16.classifier[6].in_features\n\n    vgg16.classifier[6] = nn.Linear(num_ftrs, 5).to(device)\n    \n    # Set the optimizer\n    optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)\n    exp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.01)\n    \n    print('Model was reset')\n    results, _ = engine.train_with_early_stopping(model=vgg16,\n                                                  train_dataloader=data_loaders[i][0],\n                                                  valid_dataloader=data_loaders[i][1],\n                                                  optimizer=optimizer,\n                                                  loss_fn=loss_fn,\n                                                  epochs=20,\n                                                  device=device)\n\n    results_all.append(results)\n\n    # End the timer and print out how long it took\n    end_time = timer()\n    print(f\"[INFO] Total training time of split {i}: {end_time-start_time:.3f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-09-09T19:37:33.650466Z","iopub.execute_input":"2023-09-09T19:37:33.650814Z","iopub.status.idle":"2023-09-09T20:19:34.944527Z","shell.execute_reply.started":"2023-09-09T19:37:33.650768Z","shell.execute_reply":"2023-09-09T20:19:34.943491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_all)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T20:19:34.945894Z","iopub.execute_input":"2023-09-09T20:19:34.946455Z","iopub.status.idle":"2023-09-09T20:19:35.010384Z","shell.execute_reply.started":"2023-09-09T20:19:34.946421Z","shell.execute_reply":"2023-09-09T20:19:35.009321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results_all = [{'train_loss': [0.9627946676576838, 0.5822397846290294, 0.47316639333525123, 0.39256781931309137, 0.33543502599658337, 0.2658478493857033, 0.22722875041996732, 0.15384182246634737, 0.11062711889526862, 0.11631798422005137], 'train_bal_acc': [0.6091899787304201, 0.7695229606994314, 0.8067316727870361, 0.8416224696463664, 0.8756188917531904, 0.9023958027266853, 0.9182873947947481, 0.9444922112201523, 0.9590824453324456, 0.9606721668854021], 'train_mcc': [0.5046721126978047, 0.6956659881691328, 0.7446378628782787, 0.7920744991650878, 0.8293336289326795, 0.8626430571669436, 0.8896701522631675, 0.9277549815086865, 0.9476455117508811, 0.9478035820315381], 'train_f_score': [0.5764503959844526, 0.7475695121590125, 0.7903548963336419, 0.828691154419359, 0.8606508393343952, 0.888321578937471, 0.9095704984092761, 0.9418475459051171, 0.9575628180432906, 0.9579686973158649], 'valid_loss': [0.6238692376543494, 0.5031384326079312, 0.7137555997161305, 0.6586465826805901, 0.47933869765085335, 0.6515201750923606, 0.5889947212794248, 0.597238054170328, 0.7769348428529852, 0.7356662833515335], 'valid_bal_acc': [0.7323448283742404, 0.8003693365458071, 0.7350130588365881, 0.7515209626974333, 0.8162429074193779, 0.7931173891468005, 0.8241127826421945, 0.8116691641691643, 0.7841212708859768, 0.8264171939171938], 'valid_mcc': [0.6542527203496864, 0.7256376960396212, 0.6349606740587214, 0.6848656271500496, 0.7415788773617062, 0.728045761073004, 0.761851475025364, 0.7444149840657195, 0.7031016640431386, 0.7653038862508695], 'valid_f_score': [0.6924230021534177, 0.783871282683441, 0.699959058793528, 0.7387742408302904, 0.7963891694733146, 0.7753176539884288, 0.8108325727017961, 0.8022863996063525, 0.7583216477755697, 0.8134444332136709]}, {'train_loss': [0.22094470042707948, 0.10188348116764032, 0.06340883078176857, 0.08935640290163814, 0.0726748314781991, 0.09337691453915528, 0.038807652789139814, 0.029901945856074558, 0.06315377547349164, 0.05635203638110611], 'train_bal_acc': [0.9298319552179843, 0.969838071266488, 0.9795458626340978, 0.9736874400109696, 0.9706918877690937, 0.9737570232055527, 0.9885131820793587, 0.9913834776334777, 0.9786628934790694, 0.9821724374481725], 'train_mcc': [0.9017634837735359, 0.9583535182914256, 0.9750180133129589, 0.9645811564595826, 0.9620862941927555, 0.9661723744195883, 0.985677443569525, 0.9865841350191097, 0.9719567074864883, 0.9745711663508051], 'train_f_score': [0.9213098211092859, 0.9668753151136336, 0.9801691175977185, 0.9717675983268624, 0.9697754376625564, 0.9728471006168602, 0.988694182403683, 0.9894824845854095, 0.9774755094075767, 0.979915431253171], 'valid_loss': [0.11688099746756694, 0.13029341585934162, 0.11405343343229855, 0.09423722641761689, 0.2148998506805476, 0.12187723641502946, 0.2465956368319252, 0.08732626781634548, 0.1479182612589177, 0.13273587559952454], 'valid_bal_acc': [0.9727839317545199, 0.962784437784438, 0.9659344903462551, 0.9675381318028377, 0.9235903149138442, 0.9643027723910078, 0.9286674926380811, 0.9666677276971396, 0.9470152559858441, 0.9509650480238714], 'valid_mcc': [0.9629681326678633, 0.9448460259261514, 0.9442269517652465, 0.9518112938000175, 0.8965415504251522, 0.9423298323015158, 0.8996505940744579, 0.9529406198563762, 0.924817099778222, 0.9320419251532318], 'valid_f_score': [0.9705558434798365, 0.955983688323209, 0.9550065949809566, 0.9618940477458962, 0.9142959554987553, 0.9544881483345679, 0.917136192528707, 0.9623426361154149, 0.9411880873886017, 0.9460917660315218]}, {'train_loss': [0.06762893128753229, 0.05494115112849292, 0.02613393446389476, 0.10907816171461224, 0.027126011442519752, 0.043210910971966394], 'train_bal_acc': [0.9789494839311016, 0.9817977406580349, 0.9928306538233007, 0.9735875603155015, 0.9920097875980228, 0.9873876776817951], 'train_mcc': [0.9722958314298159, 0.9780428647127299, 0.9901875779121483, 0.9639712121590098, 0.9891511712688287, 0.981923693640073], 'train_f_score': [0.9782620150489221, 0.9820108094492473, 0.9922769287690967, 0.9716387626380323, 0.9915904550206172, 0.9856016278012594], 'valid_loss': [0.020652413871550167, 0.021704104907043716, 0.0655968176707735, 0.0749868821927949, 0.030752411125885212, 0.04114580967956606], 'valid_bal_acc': [0.9935480859010272, 0.9965569561157795, 0.9811367880485529, 0.9803335879806471, 0.9898832866479924, 0.9850000000000001], 'valid_mcc': [0.9906118212571187, 0.9941054386764212, 0.972342217450547, 0.9732176264882949, 0.9880664391994429, 0.9802213955805629], 'valid_f_score': [0.9926090193459278, 0.9954433336717985, 0.9782121886896251, 0.9787484681681539, 0.9906909107003827, 0.9841428250569593]}, {'train_loss': [0.13723791189766096, 0.03477925102411331, 0.046606388449457456, 0.03756942905281047, 0.0335527715527432, 0.029309230205185218, 0.035920373059906634], 'train_bal_acc': [0.95923286272551, 0.9891662749015692, 0.9876907936834404, 0.9888941777177072, 0.9896807359307358, 0.9893433812919108, 0.9895025358628295], 'train_mcc': [0.950269607163429, 0.9852372440662457, 0.9834717907452831, 0.9855626472448141, 0.9873339127671282, 0.986428306927844, 0.9851316147449033], 'train_f_score': [0.959927854547292, 0.9882443428441481, 0.9868846505498463, 0.9884224203671972, 0.9898371301826077, 0.9891666582174231, 0.9881729379713178], 'valid_loss': [0.07403050231582978, 0.013959448302664575, 0.05595329633968718, 0.03395577842499787, 0.07638179524185355, 0.04103120454986792, 0.07244019100428833], 'valid_bal_acc': [0.9814141414141413, 0.9932539682539682, 0.9808492487904253, 0.9883356676003734, 0.9764043146396089, 0.9902334267040148, 0.9792549444020032], 'valid_mcc': [0.9767408026920523, 0.992963806982357, 0.9757883123500872, 0.9861004324562993, 0.9597633221291392, 0.9873712122100303, 0.9692021411244428], 'valid_f_score': [0.9815061486922261, 0.9942960918725239, 0.9805266200973134, 0.9889372644376275, 0.968391074026222, 0.9898412176551972, 0.9751242006462624]}, {'train_loss': [0.03633734955099713, 0.04700147283785876, 0.042516198410981705, 0.04194321836225486, 0.021643497164297837, 0.0040473770212456125, 0.051363232196208364, 0.07290867624739322, 0.06098386895802618, 0.026948013557664713], 'train_bal_acc': [0.9890944145723557, 0.9842481374834317, 0.9894665873342343, 0.9844164944532592, 0.9934261071852982, 0.9990079365079365, 0.9872722498090146, 0.9778680388239214, 0.9833868827251178, 0.9915120418796891], 'train_mcc': [0.9844102122022608, 0.9801894534300869, 0.9846994908745242, 0.977607296759242, 0.9910342756678618, 0.9985404356434461, 0.9825923782314168, 0.9701661092138624, 0.97759185830708, 0.9881811602389928], 'train_f_score': [0.9876980502944451, 0.9843925563148287, 0.9878980055494777, 0.98227107473525, 0.9929781902935175, 0.9988662950042937, 0.9861424566542984, 0.9760796425249614, 0.9823061662905994, 0.990579480171223], 'valid_loss': [0.014132972396242515, 0.03458607899494168, 0.09961753474164974, 0.011430984362959862, 0.031713323790908736, 0.004898638243342729, 0.11650880761718486, 0.044840588953400796, 0.07334855611449764, 0.036708449968821645], 'valid_bal_acc': [0.9973529411764707, 0.9932698837110602, 0.9692201426024956, 0.9969815805109924, 0.9884708428826076, 0.998235294117647, 0.964940794499618, 0.9873919870978694, 0.9792693744164334, 0.9896914523385112], 'valid_mcc': [0.9964520962755844, 0.9895101948698816, 0.9662944753411852, 0.995417112367331, 0.9861904776820731, 0.9977223668307351, 0.9557715511308457, 0.9836628181802924, 0.9729234792318794, 0.9844905563411527], 'valid_f_score': [0.9972176977611762, 0.991839540486734, 0.97322148219663, 0.996340600719926, 0.9889312676942436, 0.9981700714576102, 0.9647638778947112, 0.9870576999279791, 0.978813605073408, 0.9879748123368364]}]\n# plot cross validation's average scores on the validation splits\nimport pandas as pd\n# mean_bal_acc = np.mean([max(results_all[i]['valid_bal_acc']) for i in range(len(results_all))])\n# mean_mcc = np.mean([max(results_all[i]['valid_mcc']) for i in range(len(results_all))])\n# mean_f_score = np.mean([max(results_all[i]['valid_f_score']) for i in range(len(results_all))])\n# mean_scores = [mean_bal_acc, mean_mcc, mean_f_score]\n# score_names = ['Balanced Acc', 'MCC', 'F1 score']\nmy_dict = {'Balanced Acc': [results_all[i]['valid_bal_acc'][results_all[i]['valid_loss'].index(min(results_all[i]['valid_loss']))] for i in range(len(results_all))], \n           'MCC': [results_all[i]['valid_mcc'][results_all[i]['valid_loss'].index(min(results_all[i]['valid_loss']))] for i in range(len(results_all))], \n           'F1 score': [results_all[i]['valid_f_score'][results_all[i]['valid_loss'].index(min(results_all[i]['valid_loss']))] for i in range(len(results_all))]}\n\nmy_df = pd.DataFrame(my_dict)\nprint(my_df)\nplt.rcParams[\"figure.autolayout\"] = True\nplt.figure(figsize=(10,8))\nsns.set_style('whitegrid')\nax = sns.barplot(data= my_df, estimator=np.mean, color='blue', palette='hls', errorbar=\"sd\", capsize=.2, errwidth=1.5)\nax.bar_label(ax.containers[0], padding=15)\n\nplt.xlabel('Metrics', fontsize=15)\nplt.ylabel(f'Average values', fontsize=15)\n\nplt.suptitle(f'Average score values of 5-fold CV', fontsize=15)\nplt.savefig(f'/kaggle/working/vgg16_cv_scores.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T20:20:04.073764Z","iopub.execute_input":"2023-09-09T20:20:04.074135Z","iopub.status.idle":"2023-09-09T20:20:04.768687Z","shell.execute_reply.started":"2023-09-09T20:20:04.074105Z","shell.execute_reply":"2023-09-09T20:20:04.767735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curves of our model\nfor i in range(len(results_all)):\n    helper_functions.plot_loss_curves(results_all[i])\n    plt.savefig(f'/kaggle/working/vgg16_loss_curves_split_{i}.png')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T20:21:31.014860Z","iopub.execute_input":"2023-09-09T20:21:31.015746Z","iopub.status.idle":"2023-09-09T20:21:39.983224Z","shell.execute_reply.started":"2023-09-09T20:21:31.015685Z","shell.execute_reply":"2023-09-09T20:21:39.979861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final model\n\nTrain a final model and evaluate it on the held out test set","metadata":{}},{"cell_type":"code","source":"# train final model on the reduced set with a split 85-15 train-val\nreduced_dataset = train_subset\ntrain_indices, val_indices = train_test_split(train_idx, test_size=0.15, stratify=train_targets, random_state=42)  # set seed to ensure reproducibility\n                                              \ntrain_subset = Subset(train_dataset, train_indices)\ntrain_targets=[train_dataset.targets[i] for i in train_indices]\n                                              \nval_subset = Subset(train_dataset, val_indices)\nval_targets=[train_dataset.targets[i] for i in val_indices]\n                                              \ntrain_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:19:22.268074Z","iopub.execute_input":"2023-09-12T11:19:22.268432Z","iopub.status.idle":"2023-09-12T11:19:22.322611Z","shell.execute_reply.started":"2023-09-12T11:19:22.268405Z","shell.execute_reply":"2023-09-12T11:19:22.321320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nstart_time = timer()\n\n# Load the model and reset the final layer\nweights = models.VGG16_Weights.DEFAULT\nvgg16 = models.vgg16(weights=weights).to(device)\nnum_ftrs = vgg16.classifier[6].in_features\n\nvgg16.classifier[6] = nn.Linear(num_ftrs, 5).to(device)\n\n# Set the optimizer\noptimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)\nexp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.01)\n\nprint('Start Training of final model')\nresults, final_model = engine.train_with_early_stopping(model=vgg16,\n                                              train_dataloader=train_loader,\n                                              valid_dataloader=val_loader,\n                                              optimizer=optimizer,\n                                              loss_fn=loss_fn,\n                                              epochs=10,\n                                              device=device)\n\n\nend_time = timer()\nprint(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\\n\")\n\nMODEL_SAVE_PATH = os.path.join('/kaggle/working/', '01_vgg16_final_model.pth')\nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=final_model.state_dict(), f=MODEL_SAVE_PATH)\n                                              \nhelper_functions.plot_loss_curves(results)\nplt.savefig(f'/kaggle/working/training_curves_vgg16_final_model.png')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:48:51.418583Z","iopub.execute_input":"2023-09-12T09:48:51.418972Z","iopub.status.idle":"2023-09-12T09:56:58.211690Z","shell.execute_reply.started":"2023-09-12T09:48:51.418938Z","shell.execute_reply":"2023-09-12T09:56:58.210797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_targets)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:01:05.356755Z","iopub.execute_input":"2023-09-12T10:01:05.357687Z","iopub.status.idle":"2023-09-12T10:01:05.420302Z","shell.execute_reply.started":"2023-09-12T10:01:05.357643Z","shell.execute_reply":"2023-09-12T10:01:05.419325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test final model on the held out test set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, f1_score\n# loaded_model_vgg16 = models.vgg16()\n# loaded_model_vgg16.load_state_dict(torch.load(f=MODEL_SAVE_PATH), strict=False)\n# loaded_model_vgg16 = loaded_model_vgg16.to(device)\nloaded_model_vgg16 = final_model\n\nloaded_model_vgg16.eval()\nwith torch.inference_mode():\n    all_predictions = []\n    all_true_labels = []\n    \n    test_loss, test_bal_acc, test_mcc, test_f_score = 0, 0, 0, 0\n    for batch, (X, y) in enumerate(test_loader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        test_pred_logits = loaded_model_vgg16(X)\n\n        # 2. Calculate and accumulate loss\n        loss = loss_fn(test_pred_logits, y)\n        test_loss += loss.item()\n\n        # Calculate and accumulate scores\n        test_pred_labels = test_pred_logits.argmax(dim=1)\n        test_bal_acc += balanced_accuracy_score(y.cpu().numpy(), test_pred_labels.cpu().numpy())\n        test_mcc += matthews_corrcoef(y.cpu().numpy(), test_pred_labels.cpu().numpy())\n        test_f_score += f1_score(y.cpu().numpy(), test_pred_labels.cpu().numpy(), average='weighted')\n        \n        all_predictions.extend(test_pred_labels.cpu().numpy())\n        all_true_labels.extend(y.cpu().numpy())\n\n    # Adjust metrics to get average loss and accuracy per batch\n    test_loss = test_loss / len(test_loader)\n    test_bal_acc = test_bal_acc / len(test_loader)\n    test_mcc = test_mcc / len(test_loader)\n    test_f_score = test_f_score / len(test_loader)\n    print(f'Test loss: {test_loss} | Test bal acc {test_bal_acc} | Test mcc {test_mcc} | Test_f_score {test_f_score}\\n')   \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:01:12.142744Z","iopub.execute_input":"2023-09-12T10:01:12.143707Z","iopub.status.idle":"2023-09-12T10:01:17.633583Z","shell.execute_reply.started":"2023-09-12T10:01:12.143672Z","shell.execute_reply":"2023-09-12T10:01:17.632578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix on the test set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm = confusion_matrix(all_true_labels, all_predictions)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.savefig(f'/kaggle/working/vgg16_final_model_cm.png', dpi=300)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:01:34.120966Z","iopub.execute_input":"2023-09-12T10:01:34.121327Z","iopub.status.idle":"2023-09-12T10:01:35.401739Z","shell.execute_reply.started":"2023-09-12T10:01:34.121298Z","shell.execute_reply":"2023-09-12T10:01:35.400819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the classification report\nreport = classification_report(all_true_labels, all_predictions)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:01:42.175269Z","iopub.execute_input":"2023-09-12T10:01:42.175638Z","iopub.status.idle":"2023-09-12T10:01:42.252014Z","shell.execute_reply.started":"2023-09-12T10:01:42.175609Z","shell.execute_reply":"2023-09-12T10:01:42.250856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train final model with data augmentations on the train set","metadata":{}},{"cell_type":"code","source":"# Define train and val transformations\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:33:13.768842Z","iopub.execute_input":"2023-09-12T13:33:13.769242Z","iopub.status.idle":"2023-09-12T13:33:13.848266Z","shell.execute_reply.started":"2023-09-12T13:33:13.769212Z","shell.execute_reply":"2023-09-12T13:33:13.846361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reload training data with augmentations\ntrain_indices, val_indices = train_test_split(train_idx, test_size=0.15, stratify=train_targets, random_state=42)\n\ntrain_dataset = ImageFolder(DATA_DIR, transform=train_transforms)\nval_dataset = ImageFolder(DATA_DIR, transform=val_transforms)\n\ntrain_subset = Subset(train_dataset, train_indices)\ntrain_targets=[train_dataset.targets[i] for i in train_indices]\n                                              \nval_subset = Subset(val_dataset, val_indices)\nval_targets=[train_dataset.targets[i] for i in val_indices]\n                                              \ntrain_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T13:33:16.781571Z","iopub.execute_input":"2023-09-12T13:33:16.783097Z","iopub.status.idle":"2023-09-12T13:33:18.087796Z","shell.execute_reply.started":"2023-09-12T13:33:16.783053Z","shell.execute_reply":"2023-09-12T13:33:18.086376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nstart_time = timer()\n\n# Load the model and reset the final layer\nweights = models.VGG16_Weights.DEFAULT\nvgg16 = models.vgg16(weights=weights).to(device)\nnum_ftrs = vgg16.classifier[6].in_features\n\nvgg16.classifier[6] = nn.Linear(num_ftrs, 5).to(device)\n\n# Set the optimizer\noptimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)\nexp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.01)\n\nprint('Start Training of final model with train data augmentations')\nresults_aug, final_model_aug = engine.train_with_early_stopping(model=vgg16,\n                                                          train_dataloader=train_loader,\n                                                          valid_dataloader=val_loader,\n                                                          optimizer=optimizer,\n                                                          loss_fn=loss_fn,\n                                                          epochs=20,\n                                                          device=device)\n\n\nend_time = timer()\nprint(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\\n\")\n\nMODEL_SAVE_PATH = os.path.join('/kaggle/working/', '02_vgg16_final_model_augment.pth')\nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=final_model_aug.state_dict(), f=MODEL_SAVE_PATH)\n                                              \nhelper_functions.plot_loss_curves(results_aug)\nplt.savefig(f'/kaggle/working/training_curves_vgg16_final_model_augment.png')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:09:29.856841Z","iopub.execute_input":"2023-09-12T12:09:29.857841Z","iopub.status.idle":"2023-09-12T12:36:03.830521Z","shell.execute_reply.started":"2023-09-12T12:09:29.857793Z","shell.execute_reply":"2023-09-12T12:36:03.829414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test final model trained with data augmentations on the held out test set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, f1_score\n\nloaded_model_vgg16 = final_model_aug\n\nloaded_model_vgg16.eval()\nwith torch.inference_mode():\n    all_predictions = []\n    all_true_labels = []\n    \n    test_loss, test_bal_acc, test_mcc, test_f_score = 0, 0, 0, 0\n    for batch, (X, y) in enumerate(test_loader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        test_pred_logits = loaded_model_vgg16(X)\n\n        # 2. Calculate and accumulate loss\n        loss = loss_fn(test_pred_logits, y)\n        test_loss += loss.item()\n\n        # Calculate and accumulate scores\n        test_pred_labels = test_pred_logits.argmax(dim=1)\n        test_bal_acc += balanced_accuracy_score(y.cpu().numpy(), test_pred_labels.cpu().numpy())\n        test_mcc += matthews_corrcoef(y.cpu().numpy(), test_pred_labels.cpu().numpy())\n        test_f_score += f1_score(y.cpu().numpy(), test_pred_labels.cpu().numpy(), average='weighted')\n        \n        all_predictions.extend(test_pred_labels.cpu().numpy())\n        all_true_labels.extend(y.cpu().numpy())\n\n    # Adjust metrics to get average loss and accuracy per batch\n    test_loss = test_loss / len(test_loader)\n    test_bal_acc = test_bal_acc / len(test_loader)\n    test_mcc = test_mcc / len(test_loader)\n    test_f_score = test_f_score / len(test_loader)\n    print(f'Test loss: {test_loss} | Test bal acc {test_bal_acc} | Test mcc {test_mcc} | Test_f_score {test_f_score}\\n')   \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:37:06.725659Z","iopub.execute_input":"2023-09-12T12:37:06.726036Z","iopub.status.idle":"2023-09-12T12:37:12.753551Z","shell.execute_reply.started":"2023-09-12T12:37:06.726005Z","shell.execute_reply":"2023-09-12T12:37:12.752163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm = confusion_matrix(all_true_labels, all_predictions)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.savefig(f'/kaggle/working/vgg16_final_model_aug_cm.png', dpi=300)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:37:39.462422Z","iopub.execute_input":"2023-09-12T12:37:39.462880Z","iopub.status.idle":"2023-09-12T12:37:40.895642Z","shell.execute_reply.started":"2023-09-12T12:37:39.462846Z","shell.execute_reply":"2023-09-12T12:37:40.894470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the classification report\nreport = classification_report(all_true_labels, all_predictions)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:37:45.856568Z","iopub.execute_input":"2023-09-12T12:37:45.856975Z","iopub.status.idle":"2023-09-12T12:37:45.937847Z","shell.execute_reply.started":"2023-09-12T12:37:45.856942Z","shell.execute_reply":"2023-09-12T12:37:45.936056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Explainability using GradCam","metadata":{}},{"cell_type":"code","source":"def load_trained_vgg16(path, device):\n    weights = models.VGG16_Weights.DEFAULT\n    loaded_model_vgg16 = models.vgg16(weights=weights).to(device)\n    num_ftrs = loaded_model_vgg16.classifier[6].in_features\n\n    loaded_model_vgg16.classifier[6] = nn.Linear(num_ftrs, 5).to(device)\n    loaded_model_vgg16.load_state_dict(torch.load(f=path, map_location=torch.device(device)), strict=False)\n    loaded_model_vgg16 = loaded_model_vgg16.to(device)\n    \n    return loaded_model_vgg16\n\nmodel_path = os.path.join('/kaggle/input/trained-vgg16-models', '02_vgg16_final_model_augment(1).pth')\nmodel = load_trained_vgg16(model_path, device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:14:50.539509Z","iopub.execute_input":"2023-09-13T08:14:50.539818Z","iopub.status.idle":"2023-09-13T08:15:00.137690Z","shell.execute_reply.started":"2023-09-13T08:14:50.539797Z","shell.execute_reply":"2023-09-13T08:15:00.136819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install grad-cam","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:15:06.443042Z","iopub.execute_input":"2023-09-13T08:15:06.443434Z","iopub.status.idle":"2023-09-13T08:15:29.179730Z","shell.execute_reply.started":"2023-09-13T08:15:06.443400Z","shell.execute_reply":"2023-09-13T08:15:29.178559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM\nfrom PIL import Image\n\nfrom torchvision.transforms.functional import to_tensor\nfrom pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n\nimport cv2 \n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T09:24:32.121723Z","iopub.execute_input":"2023-09-13T09:24:32.122124Z","iopub.status.idle":"2023-09-13T09:24:32.171643Z","shell.execute_reply.started":"2023-09-13T09:24:32.122096Z","shell.execute_reply":"2023-09-13T09:24:32.170905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_filenames = ['/kaggle/input/fungi-all/H1/H1_100a_1.jpg.jpg',\n                   '/kaggle/input/fungi-all/H2/H2_103b_2.jpg.jpg',\n                   '/kaggle/input/fungi-all/H3/H3_10a_3.jpg.jpg',\n                   '/kaggle/input/fungi-all/H5/H5_103a_2.jpg.jpg',\n                   '/kaggle/input/fungi-all/H6/H6_12a_3.jpg.jpg'\n                  ]\n\nvgg16_layer = model.features[-1] # this is the target layer that we want grad cam to use its feature map and generate the Grad-CAM heatmaps\n\ndef show(imgs, title):\n    sub_plot_titles = ['Original Image', 'GradCam', 'Heatmap']\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n        \n    plt.rcParams[\"figure.figsize\"] = [7.50, 3]\n    fig, axs = plt.subplots(1, len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        axs[0, i].imshow(img)\n        axs[0, i].set_title(sub_plot_titles[i])\n        axs[0, i].grid(False)\n        axs[0, i].axis('off')\n        \n    fig.suptitle(title)\n    plt.grid(False)\n    plt.axis('off')\n    plt.show()\n    \n    \ndef reshape_transform(tensor, height=14, width=14):\n    # This function transforms the tensors of Vit to use them with Grad Cam similarly as the results of CNN models\n    result = tensor[:, 1:, :].reshape(tensor.size(0),\n                                      height, width, tensor.size(2))\n\n    # Bring the channels to the first dimension,\n    # like in CNNs.\n    result = result.transpose(2, 3).transpose(1, 2)\n    return result\n    \n    \ndef visualize_gradcam(model, layer, device, filenames, vit=False):\n    for idx, class_name in enumerate(['H1', 'H2', 'H3', 'H5', 'H6']):\n        model.eval()\n\n        img = np.array(Image.open(filenames[idx]))\n        img = cv2.resize(img, (224, 224))\n        img = np.float32(img) / 255\n        input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n        if device == 'cuda':\n            use_cuda = True\n        else:\n            use_cuda = False\n\n        # The target for the CAM is the class of each image.\n        # As usual for classication, the target is the logit output\n        # before softmax, for that category.\n        target_layers = [layer]\n        targets = [ClassifierOutputTarget(idx)] \n        \n        if vit:\n            with GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda, reshape_transform=reshape_transform) as cam:\n                grayscale_cams = cam(input_tensor=input_tensor.to(device), targets=targets, aug_smooth=True)\n                cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n        else:\n            with GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda) as cam:\n                grayscale_cams = cam(input_tensor=input_tensor.to(device), targets=targets, aug_smooth=True)\n                cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n\n        cam = np.uint8(255*grayscale_cams[0, :])\n        cam = cv2.merge([cam, cam, cam])\n        # images = np.hstack((np.uint8(255*img), cam , cam_image))\n        images = [np.uint8(255*img), cam , cam_image]\n        show(images, f'{class_name} class explainability')\n        # Image.fromarray(images)\n        \nvisualize_gradcam(model, vgg16_layer, device, image_filenames)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T09:24:34.384215Z","iopub.execute_input":"2023-09-13T09:24:34.384866Z","iopub.status.idle":"2023-09-13T09:25:01.687872Z","shell.execute_reply.started":"2023-09-13T09:24:34.384822Z","shell.execute_reply":"2023-09-13T09:25:01.686326Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}